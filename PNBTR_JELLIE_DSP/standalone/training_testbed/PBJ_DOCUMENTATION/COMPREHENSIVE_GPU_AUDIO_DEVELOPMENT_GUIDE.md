# COMPREHENSIVE GPU AUDIO DEVELOPMENT GUIDE

**PNBTR+JELLIE Training Testbed - Complete Development Reference**

> **üéØ DEFINITIVE GUIDE:**  
> This document combines proven video game engine architecture patterns with GPU-accelerated Metal shader development, JUCE integration, and CMake build configuration. Includes all lessons learned from actual implementation to avoid repeating past mistakes.

---

## üìä **CORE ARCHITECTURAL PRINCIPLES**

### **Game Engine Inspired Architecture**

Apply proven video game engine patterns (Unity, Unreal, Godot) to create high-performance, real-time Digital Audio Workstation (DAW) engines. This leverages decades of game engine optimization for low-latency, multi-threaded, GPU-accelerated audio processing.

#### **1. Frame Pacing & Real-Time Loops**

**Pattern**: Unity's fixed vs variable timestep, Unreal's sub-stepped physics  
**Application**: Separate audio processing (fixed timestep) from UI rendering (variable timestep)

```cpp
class AudioEngine {
    // Fixed timestep - CRITICAL for audio (like Unity's FixedUpdate)
    void audioCallback(int bufferSize) {
        // Runs at precise intervals (e.g. every 2.9ms for 128 samples @ 48kHz)
        // NEVER allowed to miss deadline
        processAudioBlock(bufferSize);
    }

    // Variable timestep - degradable performance (like Unity's Update)
    void renderUI(double deltaTime) {
        // Can drop frames if CPU is busy
        // UI updates at 60fps, audio continues at fixed rate
        updateVisualization(deltaTime);
    }
};
```

#### **2. Thread Separation Architecture**

**Pattern**: Unreal's render thread, Unity's job system separation  
**Application**: High-priority audio thread isolated from UI/graphics threads

```cpp
class DAWEngineThreads {
private:
    std::thread audioThread;
    std::thread uiThread;
    ThreadPool dspWorkerPool;

public:
    void initializeThreads() {
        audioThread = std::thread([this]() {
            setRealTimePriority();
            audioProcessingLoop();
        });

        uiThread = std::thread([this]() {
            uiRenderLoop();
        });
    }

    void processAudioBlock() {
        // Dispatch heavy DSP work to worker threads
        dspWorkerPool.dispatch([this]() {
            MetalBridge::getInstance().processGPUPipeline();
        });
    }
};
```

#### **3. Entity-Component System (ECS) for DSP**

**Pattern**: Unity DOTS, Unreal's component architecture  
**Application**: Modular DSP nodes with hot-swappable components

```cpp
class DSPNode {
    uint32_t entityID;
    std::vector<std::unique_ptr<DSPComponent>> components;

    template<typename T>
    void addComponent() {
        components.push_back(std::make_unique<T>());
    }
};

class DSPGraph {
    std::vector<DSPNode> nodes;
    std::vector<Connection> connections;

public:
    void processGraph() {
        for (auto& node : sortedByDependency(nodes)) {
            for (auto& component : node.components) {
                component->processBlock(currentBuffer);
            }
        }
    }
};
```

---

## üöÄ **METAL GPU COMPUTE PIPELINE**

### **üéµ Complete Audio Pipeline Flow**

```
Core Audio Input ‚Üí JUCE AudioIOCallback ‚Üí MetalBridge ‚Üí GPU Shaders ‚Üí Audio Output
     ‚Üì                    ‚Üì                    ‚Üì              ‚Üì              ‚Üì
  Microphone         Convert to float      Upload to       Process in      Convert back
  Hardware           buffers               GPU memory      parallel        to output
```

**Critical Pipeline Components:**

1. **Input Capture** ‚Üí Record-armed audio capture with gain control
2. **Input Gating** ‚Üí Noise suppression and signal detection
3. **Spectral Analysis** ‚Üí DJ-style real-time FFT with color mapping
4. **JELLIE Preprocessing** ‚Üí Prepare audio for neural processing
5. **Network Simulation** ‚Üí Simulate packet loss and jitter
6. **PNBTR Reconstruction** ‚Üí Neural prediction and audio restoration
7. **Visual Feedback** ‚Üí Real-time spectrum and waveform display

### **üéØ Core Metal Shader Components**

#### **1. Audio Input Capture Pipeline**

```metal
// AudioInputCaptureShader.metal
#include <metal_stdlib>
using namespace metal;

struct InputCaptureUniforms {
    uint armed;            // 0 = unarmed, 1 = armed for recording
    uint writeIndex;       // Ring buffer write head position
    uint bufferSizeFrames; // Total ring buffer size (power of 2)
    float gainLevel;       // Input gain multiplier (0.0 - 2.0)
    float armPulse;        // Visual pulse when armed (0.0 - 1.0)
};

kernel void audioInputCaptureKernel(
    constant InputCaptureUniforms& uniforms [[buffer(0)]],
    device const float2*           inputAudio  [[buffer(1)]],
    device float2*                 ringBuffer  [[buffer(2)]],
    device float*                  levelMeter  [[buffer(3)]],
    uint frameID                               [[thread_position_in_grid]])
{
    if (uniforms.armed == 0) return;

    uint writePos = (uniforms.writeIndex + frameID) % uniforms.bufferSizeFrames;
    float2 sample = inputAudio[frameID] * uniforms.gainLevel;

    // Write to ring buffer
    ringBuffer[writePos] = sample;

    // Update level meter (peak detection)
    float peak = max(abs(sample.x), abs(sample.y));
    levelMeter[frameID] = peak;
}
```

#### **2. Input Gating & Signal Detection**

```metal
// AudioInputGateShader.metal
struct InputGateUniforms {
    uint armed;
    float threshold;       // Volume gate threshold (0.0 - 1.0)
    float attackTime;      // Gate attack time in samples
    float releaseTime;     // Gate release time in samples
    uint frameOffset;
};

kernel void audioInputGateKernel(
    constant InputGateUniforms& uniforms [[buffer(0)]],
    device float2*              ringBuffer [[buffer(1)]],
    device uint*                gateState  [[buffer(2)]], // 0 = gated, 1 = open
    device float*               envelope   [[buffer(3)]], // Smoothed gate envelope
    uint frameID                           [[thread_position_in_grid]])
{
    if (uniforms.armed == 0) {
        gateState[frameID] = 0;
        envelope[frameID] = 0.0;
        return;
    }

    float2 sample = ringBuffer[uniforms.frameOffset + frameID];
    float amplitude = max(abs(sample.x), abs(sample.y));

    // Gate logic with hysteresis
    bool shouldOpen = amplitude > uniforms.threshold;
    gateState[frameID] = shouldOpen ? 1 : 0;

    // Smooth envelope for click-free gating
    float targetEnv = shouldOpen ? 1.0 : 0.0;
    float rate = shouldOpen ? (1.0 / uniforms.attackTime) : (1.0 / uniforms.releaseTime);
    envelope[frameID] = mix(envelope[frameID], targetEnv, rate);
}
```

#### **3. DJ-Style Real-Time Spectral Analysis**

```metal
// DJSpectralAnalysisShader.metal
struct SpectralUniforms {
    uint fftSize;          // 1024, 2048, etc. (power of 2)
    float maxMagnitude;    // Dynamic range scaling
    float4 bassColor;      // Low frequency color (20Hz - 250Hz)
    float4 midColor;       // Mid frequency color (250Hz - 4kHz)
    float4 trebleColor;    // High frequency color (4kHz - 20kHz)
    float sampleRate;      // For frequency bin mapping
};

// Step 1: Compute FFT magnitudes
kernel void djFFTComputeKernel(
    constant SpectralUniforms& uniforms [[buffer(0)]],
    device const float*        audioBuffer  [[buffer(1)]],
    device float*              spectrumBins [[buffer(2)]],
    uint threadID                           [[thread_position_in_grid]])
{
    const uint half = uniforms.fftSize / 2;
    if (threadID >= half) return;

    // Real FFT computation (simplified - use Metal Performance Shaders for production)
    float real = audioBuffer[threadID];
    float imag = audioBuffer[threadID + half];
    float magnitude = sqrt(real * real + imag * imag);

    // Logarithmic scaling for better visual distribution
    float logMag = log10(magnitude + 1e-10) / log10(uniforms.maxMagnitude + 1e-10);
    spectrumBins[threadID] = clamp(logMag, 0.0, 1.0);
}

// Step 2: Render DJ-style spectrum visualization
kernel void djSpectrumVisualKernel(
    constant SpectralUniforms& uniforms [[buffer(0)]],
    device const float*        bins      [[buffer(1)]],
    texture2d<float, access::write> outTexture [[texture(0)]],
    uint2 gid                                   [[thread_position_in_grid]])
{
    uint width = outTexture.get_width();
    uint height = outTexture.get_height();

    float xNorm = float(gid.x) / float(width);
    uint binIndex = min(uint(xNorm * (uniforms.fftSize / 2)), (uniforms.fftSize / 2) - 1);
    float magnitude = bins[binIndex];

    // Frequency-based color mapping (DJ-style)
    float frequency = (float(binIndex) / float(uniforms.fftSize)) * uniforms.sampleRate;
    float4 color;

    if (frequency < 250.0) {
        // Bass frequencies - red/orange
        color = uniforms.bassColor;
    } else if (frequency < 4000.0) {
        // Mid frequencies - green/yellow
        float midMix = (frequency - 250.0) / (4000.0 - 250.0);
        color = mix(uniforms.bassColor, uniforms.midColor, midMix);
    } else {
        // Treble frequencies - blue/cyan
        float trebleMix = min((frequency - 4000.0) / (20000.0 - 4000.0), 1.0);
        color = mix(uniforms.midColor, uniforms.trebleColor, trebleMix);
    }

    // Vertical bar rendering
    float yNorm = float(gid.y) / float(height);
    if (yNorm > (1.0 - magnitude)) {
        // Scale color intensity with magnitude
        outTexture.write(color * magnitude, gid);
    } else {
        // Background with subtle grid
        float4 bgColor = (gid.x % 20 == 0 || gid.y % 20 == 0) ?
                        float4(0.1, 0.1, 0.1, 1.0) : float4(0.0, 0.0, 0.0, 1.0);
        outTexture.write(bgColor, gid);
    }
}
```

#### **4. Record-Arm Visual Feedback**

```metal
// RecordArmVisualShader.metal
struct RecordArmUniforms {
    float4 armColor;       // Record arm glow color (typically red)
    float pulseIntensity;  // Pulse animation intensity (0.0 - 1.0)
    float time;            // Animation time for pulsing effect
    uint armed;            // Armed state
};

kernel void recordArmVisualKernel(
    constant RecordArmUniforms& uniforms [[buffer(0)]],
    texture2d<float, access::read>  baseTexture [[texture(0)]],
    texture2d<float, access::write> outTexture  [[texture(1)]],
    uint2 gid                                    [[thread_position_in_grid]])
{
    float4 basePixel = baseTexture.read(gid);

    if (uniforms.armed == 0) {
        outTexture.write(basePixel, gid);
        return;
    }

    // Animated pulse effect
    float pulse = 0.5 + 0.5 * sin(uniforms.time * 3.14159 * 2.0); // 1 Hz pulse
    float glowIntensity = uniforms.pulseIntensity * pulse;

    // Apply glow overlay
    float4 glowPixel = basePixel + (uniforms.armColor * glowIntensity);
    outTexture.write(glowPixel, gid);
}
```

#### **5. JELLIE Audio Preprocessing**

```metal
// JELLIEPreprocessShader.metal
struct JELLIEUniforms {
    uint frameStartIndex;
    float sampleRate;
    uint64_t baseTimestampNs;
    float quantizationLevel;   // 24-bit: 8388608.0, 16-bit: 32768.0
    uint channelMask;          // 8-channel JDAT distribution
};

struct JELLIESample {
    float sample;
    uint64_t timestampOffset;
    uint channelMask;
    float originalLevel;       // For SNR calculation
};

kernel void jelliePreprocessKernel(
    constant JELLIEUniforms& uniforms [[buffer(0)]],
    device const float2*     ringBuffer [[buffer(1)]],
    device const float*      gateEnvelope [[buffer(2)]],
    device JELLIESample*     outSamples [[buffer(3)]],
    uint frameID                        [[thread_position_in_grid]])
{
    float2 stereoSample = ringBuffer[uniforms.frameStartIndex + frameID];
    float gateLevel = gateEnvelope[frameID];

    // Convert to mono with gating applied
    float mono = 0.5 * (stereoSample.x + stereoSample.y) * gateLevel;

    // Quantize to target bit depth
    float quantized = round(mono * uniforms.quantizationLevel) / uniforms.quantizationLevel;

    JELLIESample js;
    js.sample = quantized;
    js.originalLevel = mono; // Store original for quality metrics
    js.timestampOffset = uint64_t(frameID * (1e9 / uniforms.sampleRate));
    js.channelMask = frameID % 8; // Distribute across 8 JDAT channels

    outSamples[frameID] = js;
}
```

#### **6. Network Simulation & Packet Loss**

```metal
// NetworkSimulationShader.metal
struct NetworkUniforms {
    uint packetLossPercentage; // 0-100
    float jitterAmountMs;
    uint networkSeed;
    float latencyMs;
};

kernel void networkSimulationKernel(
    constant NetworkUniforms& uniforms [[buffer(0)]],
    device const JELLIESample* inSamples    [[buffer(1)]],
    device JELLIESample*       outSamples   [[buffer(2)]],
    device uint*               lossPattern  [[buffer(3)]],
    device float*              jitterDelays [[buffer(4)]],
    uint frameID                            [[thread_position_in_grid]])
{
    // Pseudo-random number generation for deterministic testing
    uint seed = uniforms.networkSeed + frameID;
    uint rng = ((seed * 1103515245) + 12345) & 0x7fffffff;

    // Simulate packet loss
    uint lossChance = rng % 100;
    bool isLost = lossChance < uniforms.packetLossPercentage;

    if (isLost) {
        // Mark packet as lost
        JELLIESample lostSample = {0.0, 0, 0xFF, 0.0}; // Special loss marker
        outSamples[frameID] = lostSample;
        lossPattern[frameID] = 1;
        jitterDelays[frameID] = 0.0;
    } else {
        // Simulate jitter
        float jitter = (float(rng % 1000) / 1000.0 - 0.5) * uniforms.jitterAmountMs;
        outSamples[frameID] = inSamples[frameID];
        lossPattern[frameID] = 0;
        jitterDelays[frameID] = jitter;
    }
}
```

#### **7. PNBTR Neural Reconstruction**

```metal
// PNBTRReconstructionShader.metal
struct PNBTRUniforms {
    float neuralThreshold;     // Reconstruction confidence threshold
    uint lookbackSamples;      // Context window for prediction (default: 10)
    float smoothingFactor;     // Temporal smoothing (0.0 - 1.0)
};

kernel void pnbtrReconstructionKernel(
    constant PNBTRUniforms& uniforms [[buffer(0)]],
    device const JELLIESample* networkSamples [[buffer(1)]],
    device const uint*         lossPattern    [[buffer(2)]],
    device float*              reconstructedAudio [[buffer(3)]],
    device float*              qualityMetrics [[buffer(4)]], // SNR, error metrics
    uint frameID                               [[thread_position_in_grid]])
{
    if (lossPattern[frameID] == 0) {
        // No loss - direct copy
        reconstructedAudio[frameID] = networkSamples[frameID].sample;
        qualityMetrics[frameID] = 1.0; // Perfect quality
    } else {
        // Neural prediction for lost samples
        float prediction = 0.0;
        float weightSum = 0.0;

        // Weighted prediction based on nearby samples
        for (uint i = 1; i <= uniforms.lookbackSamples && frameID >= i; i++) {
            if (lossPattern[frameID - i] == 0) {
                float weight = 1.0 / float(i); // Closer samples have more weight
                prediction += networkSamples[frameID - i].sample * weight;
                weightSum += weight;
            }
        }

        if (weightSum > 0.0) {
            prediction /= weightSum;
            prediction *= uniforms.neuralThreshold;

            // Apply temporal smoothing
            if (frameID > 0) {
                float prevSample = reconstructedAudio[frameID - 1];
                prediction = mix(prevSample, prediction, uniforms.smoothingFactor);
            }

            reconstructedAudio[frameID] = prediction;
            qualityMetrics[frameID] = weightSum / float(uniforms.lookbackSamples); // Quality estimate
        } else {
            reconstructedAudio[frameID] = 0.0;
            qualityMetrics[frameID] = 0.0; // No quality
        }
    }
}
```

### **üîó MetalBridge Audio Pipeline Integration**

```cpp
class MetalBridge {
public:
    static MetalBridge& getInstance() {
        static MetalBridge instance;
        return instance;
    }

    void initialize() {
        device = MTLCreateSystemDefaultDevice();
        commandQueue = [device newCommandQueue];
        library = [device newDefaultLibrary];

        // Load all compute kernels with updated names
        loadKernel("audioInputCaptureKernel");
        loadKernel("audioInputGateKernel");
        loadKernel("djFFTComputeKernel");
        loadKernel("djSpectrumVisualKernel");
        loadKernel("recordArmVisualKernel");
        loadKernel("jelliePreprocessKernel");
        loadKernel("networkSimulationKernel");
        loadKernel("pnbtrReconstructionKernel");

        // Pre-allocate GPU buffers (CRITICAL: no real-time allocation)
        allocateGPUBuffers();
    }

    void processAudioBlock(const juce::AudioBuffer<float>& inputBuffer) {
        // CRITICAL: Thread-safe GPU processing pipeline
        std::lock_guard<std::mutex> lock(metalMutex);

        // Step 1: Convert JUCE buffer to GPU format and capture
        uploadInputToGPU(inputBuffer);

        // Step 2: Capture audio input with record-arm gating
        captureAudioInput();

        // Step 3: Apply input gating and envelope smoothing
        processInputGating();

        // Step 4: Compute DJ-style spectral analysis
        computeSpectralAnalysis();

        // Step 5: Preprocess for JELLIE encoding
        preprocessForJELLIE();

        // Step 6: Simulate network conditions
        simulateNetworkTransmission();

        // Step 7: Reconstruct audio using PNBTR
        reconstructWithPNBTR();

        // Step 8: Update visual feedback and metrics
        updateVisualizationTextures();
    }

    // CRITICAL: Get reconstructed audio for JUCE output
    void getReconstructedAudio(float** outputChannelData, int numChannels, int numSamples) {
        // Download GPU reconstruction results to CPU for JUCE output
        downloadOutputFromGPU(outputChannelData, numChannels, numSamples);
    }

private:
    id<MTLDevice> device;
    id<MTLCommandQueue> commandQueue;
    id<MTLLibrary> library;
    std::mutex metalMutex; // REQUIRED for thread safety
    std::unordered_map<std::string, id<MTLComputePipelineState>> kernels;

    // Pre-allocated GPU buffers (no real-time allocation)
    id<MTLBuffer> inputAudioBuffer;
    id<MTLBuffer> reconstructedBuffer;
    id<MTLBuffer> stagingBuffer; // For CPU-GPU transfer

    void uploadInputToGPU(const juce::AudioBuffer<float>& inputBuffer) {
        // CRITICAL: Copy JUCE audio data to GPU memory
        float* gpuData = (float*)inputAudioBuffer.contents;
        int numSamples = inputBuffer.getNumSamples();
        int numChannels = std::min(inputBuffer.getNumChannels(), 2);

        // Interleave stereo data for GPU processing
        for (int sample = 0; sample < numSamples; ++sample) {
            gpuData[sample * 2] = inputBuffer.getSample(0, sample);
            gpuData[sample * 2 + 1] = numChannels > 1 ?
                inputBuffer.getSample(1, sample) :
                inputBuffer.getSample(0, sample);
        }
    }

    void downloadOutputFromGPU(float** outputChannelData, int numChannels, int numSamples) {
        // CRITICAL: Copy GPU reconstruction results to JUCE output
        float* gpuData = (float*)reconstructedBuffer.contents;

        for (int channel = 0; channel < numChannels; ++channel) {
            for (int sample = 0; sample < numSamples; ++sample) {
                // De-interleave GPU data back to JUCE channels
                outputChannelData[channel][sample] = gpuData[sample * 2 + (channel % 2)];
            }
        }
    }
};
```

---

## üîß **JUCE INTEGRATION PATTERNS**

### **Critical Lessons Learned**

#### **‚ùå NEVER USE - Common Mistakes**

- `std::vector<float>` in real-time audio callbacks (causes heap corruption)
- Atomic operations on structs with string members (use mutex instead)
- DSP processing on JUCE Message thread (causes UI freezing)
- `jmin/jmax` functions (deprecated, use `std::min/max/clamp`)
- Missing address-of operator for `addAndMakeVisible` calls

#### **‚úÖ ALWAYS USE - Proven Patterns**

- Stack arrays `float array[4096]` for audio buffers
- `std::min(bufferSize, SAFE_BUFFER_SIZE)` for bounds checking
- `std::memset(array, 0, sizeof(array))` for zero initialization
- Separate audio thread via `AudioIODeviceCallback`
- Lock-free atomic variables for UI ‚Üî Audio thread communication

### **MetalBridge Singleton - Production Ready**

```cpp
class MetalBridge {
public:
    static MetalBridge& getInstance() {
        static MetalBridge instance;
        return instance;
    }

    void initialize() {
        device = MTLCreateSystemDefaultDevice();
        commandQueue = [device newCommandQueue];
        library = [device newDefaultLibrary];

        // Load all compute kernels with updated names
        loadKernel("audioInputCaptureKernel");
        loadKernel("audioInputGateKernel");
        loadKernel("djFFTComputeKernel");
        loadKernel("djSpectrumVisualKernel");
        loadKernel("recordArmVisualKernel");
        loadKernel("jelliePreprocessKernel");
        loadKernel("networkSimulationKernel");
        loadKernel("pnbtrReconstructionKernel");

        // Pre-allocate GPU buffers (CRITICAL: no real-time allocation)
        allocateGPUBuffers();
    }

    void processAudioBlock(const juce::AudioBuffer<float>& inputBuffer) {
        // CRITICAL: Thread-safe GPU processing
        std::lock_guard<std::mutex> lock(metalMutex);

        captureAudio(inputBuffer);
        preprocessJellie();
        simulateNetwork();
        reconstructPNBTR();
        updateVisuals();
    }

private:
    id<MTLDevice> device;
    id<MTLCommandQueue> commandQueue;
    id<MTLLibrary> library;
    std::mutex metalMutex; // REQUIRED for thread safety
    std::unordered_map<std::string, id<MTLComputePipelineState>> kernels;
};
```

### **Thread-Safe Parameter Management**

```cpp
// LESSON LEARNED: NetworkMetrics needs mutex, not atomic
struct NetworkMetrics {
    float latency;
    float packetLoss;
    float jitter;
    std::string statusMessage; // Strings can't be atomic!
};

class PNBTRTrainer : public juce::AudioIODeviceCallback {
public:
    void audioDeviceIOCallback(const float** inputChannelData, int numInputChannels,
                              float** outputChannelData, int numOutputChannels,
                              int numSamples) override {
        // CRITICAL: Real-time thread - no locks, no allocation

        // Step 1: Convert Core Audio input to JUCE buffer
        juce::AudioBuffer<float> inputBuffer(const_cast<float**>(inputChannelData),
                                           numInputChannels, numSamples);

        // Step 2: Process through GPU pipeline
        MetalBridge::getInstance().processAudioBlock(inputBuffer);

        // Step 3: Update parameters (atomic only - no locks!)
        updateAtomicParameters();

        // Step 4: Get reconstructed audio from GPU for output
        MetalBridge::getInstance().getReconstructedAudio(outputChannelData,
                                                        numOutputChannels,
                                                        numSamples);

        // Step 5: Update performance metrics
        updatePerformanceMetrics();
    }

    // Thread-safe parameter updates from UI
    void setPacketLossPercentage(float percentage) {
        packetLossPercentage.store(std::clamp(percentage, 0.0f, 100.0f));
    }

    void setJitterAmount(float jitterMs) {
        jitterAmount.store(std::clamp(jitterMs, 0.0f, 50.0f));
    }

    void setRecordArmed(bool armed) {
        recordingActive.store(armed);
    }

    // Thread-safe network metrics access (uses mutex for complex data)
    NetworkMetrics getNetworkMetrics() {
        std::lock_guard<std::mutex> lock(metricsMutex);
        return currentMetrics;
    }

    // Audio device setup
    void prepareToPlay(int samplesPerBlockExpected, double sampleRate) override {
        // Initialize MetalBridge before audio starts
        MetalBridge::getInstance().initialize();

        // Store audio parameters
        currentSampleRate = sampleRate;
        currentBlockSize = samplesPerBlockExpected;

        // Update GPU uniforms with audio format
        updateGPUAudioFormat();
    }

    void releaseResources() override {
        // Clean shutdown of GPU resources
        MetalBridge::getInstance().cleanup();
    }

private:
    // Real-time safe atomic parameters
    std::atomic<float> packetLossPercentage{2.0f};
    std::atomic<float> jitterAmount{1.0f};
    std::atomic<bool> recordingActive{false};
    std::atomic<bool> trainingActive{false};

    // Audio format tracking
    double currentSampleRate = 48000.0;
    int currentBlockSize = 256;

    // LESSON LEARNED: Mutex required for complex data structures
    std::mutex metricsMutex;
    NetworkMetrics currentMetrics;

    void updateAtomicParameters() {
        // Update GPU parameters from atomic values (no locks!)
        // This is called from real-time audio thread
        MetalBridge::getInstance().updateParameters(
            packetLossPercentage.load(),
            jitterAmount.load(),
            recordingActive.load()
        );
    }

    void updatePerformanceMetrics() {
        // Calculate real-time performance metrics
        // Update thread-safe metrics structure
        std::lock_guard<std::mutex> lock(metricsMutex);

        // Update latency, quality, packet loss statistics
        currentMetrics.latency = calculateCurrentLatency();
        currentMetrics.packetLoss = packetLossPercentage.load();
        currentMetrics.jitter = jitterAmount.load();
        currentMetrics.statusMessage = recordingActive.load() ?
            "Recording Active" : "Standby";
    }

    void updateGPUAudioFormat() {
        // Configure GPU shaders with current audio format
        MetalBridge::getInstance().setAudioFormat(currentSampleRate, currentBlockSize);
    }

    float calculateCurrentLatency() {
        // Calculate round-trip latency through GPU pipeline
        return (float(currentBlockSize) / float(currentSampleRate)) * 1000.0f; // ms
    }
};
```

### **SpectralAudioTrack Component**

```cpp
class SpectralAudioTrack : public juce::Component, public juce::Timer {
public:
    SpectralAudioTrack(const juce::String& trackName) {
        // LESSON LEARNED: Use address-of operator
        addAndMakeVisible(&nameLabel);
        addAndMakeVisible(&waveformDisplay);
        addAndMakeVisible(&spectralDisplay);

        nameLabel.setText(trackName, juce::dontSendNotification);
        startTimer(33); // 30 FPS updates
    }

    void setTrainer(PNBTRTrainer* trainer) {
        pnbtrTrainer = trainer;

        // Initialize FFT for spectral analysis
        fft = std::make_unique<juce::dsp::FFT>(10); // 1024 point FFT
        window = std::make_unique<juce::dsp::WindowingFunction<float>>(
            1024, juce::dsp::WindowingFunction<float>::hann);
    }

private:
    std::unique_ptr<juce::dsp::FFT> fft;
    std::unique_ptr<juce::dsp::WindowingFunction<float>> window;
    PNBTRTrainer* pnbtrTrainer = nullptr;
    juce::Label nameLabel;
    WaveformDisplay waveformDisplay;
    SpectralDisplay spectralDisplay;
};
```

---

## üì¶ **CMAKE CONFIGURATION - PRODUCTION READY**

### **Complete CMakeLists.txt**

```cmake
cmake_minimum_required(VERSION 3.22)
project(PnbtrJellieTrainer VERSION 1.0.0)

# LESSON LEARNED: Set C++ standard early
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# Find required packages
find_package(PkgConfig REQUIRED)

# LESSON LEARNED: Find JUCE first, then add Metal
find_package(juce CONFIG REQUIRED)

# LESSON LEARNED: Metal frameworks must be found
if(APPLE)
    find_library(METAL_FRAMEWORK Metal)
    find_library(METALKIT_FRAMEWORK MetalKit)
    find_library(METALPERFORMANCESHADERS_FRAMEWORK MetalPerformanceShaders)

    if(NOT METAL_FRAMEWORK)
        message(FATAL_ERROR "Metal framework not found")
    endif()
endif()

# Create executable
juce_add_gui_app(PnbtrJellieTrainer
    COMPANY_NAME "JAMNet"
    PRODUCT_NAME "PNBTR+JELLIE Training Testbed"
    VERSION ${PROJECT_VERSION}
    BUNDLE_ID "com.jamnet.pnbtrjellietrainer"
)

# Add source files
target_sources(PnbtrJellieTrainer PRIVATE
    Source/Main.cpp
    Source/MainComponent.cpp
    Source/PNBTRTrainer.cpp
    Source/MetalBridge.mm
    Source/GUI/ProfessionalTransportController.cpp
    Source/GUI/OscilloscopeRow.cpp
    Source/GUI/TOASTNetworkOscilloscope.cpp
    Source/GUI/SpectralAudioTrack.cpp
    Source/GUI/MetricsDashboard.cpp
)

# LESSON LEARNED: Include juce_dsp for FFT functionality
target_link_libraries(PnbtrJellieTrainer PRIVATE
    juce::juce_gui_extra
    juce::juce_audio_utils
    juce::juce_audio_devices
    juce::juce_dsp  # CRITICAL: Required for FFT
)

# LESSON LEARNED: Link Metal frameworks after JUCE
if(APPLE)
    target_link_libraries(PnbtrJellieTrainer PRIVATE
        ${METAL_FRAMEWORK}
        ${METALKIT_FRAMEWORK}
        ${METALPERFORMANCESHADERS_FRAMEWORK}
    )
endif()

# LESSON LEARNED: JUCE compile definitions
target_compile_definitions(PnbtrJellieTrainer PRIVATE
    JUCE_WEB_BROWSER=0
    JUCE_USE_CURL=0
    JUCE_APPLICATION_NAME_STRING="$<TARGET_PROPERTY:PnbtrJellieTrainer,JUCE_PRODUCT_NAME>"
    JUCE_APPLICATION_VERSION_STRING="$<TARGET_PROPERTY:PnbtrJellieTrainer,JUCE_VERSION>"
    JUCE_DISPLAY_SPLASH_SCREEN=0
    JUCE_USE_DARK_SPLASH_SCREEN=1
    JUCE_USE_METAL=1
    JUCE_ENABLE_OPENGL=0  # Avoid conflicts with Metal
)

# Metal shader compilation
function(compile_metal_shaders)
    set(METAL_SHADERS
        AudioInputCaptureShader.metal
        AudioInputGateShader.metal
        DJSpectralAnalysisShader.metal
        RecordArmVisualShader.metal
        JELLIEPreprocessShader.metal
        NetworkSimulationShader.metal
        PNBTRReconstructionShader.metal
        MetricsComputeShader.metal
    )

    foreach(SHADER ${METAL_SHADERS})
        get_filename_component(SHADER_NAME ${SHADER} NAME_WE)
        set(INPUT_FILE "${CMAKE_CURRENT_SOURCE_DIR}/shaders/${SHADER}")
        set(OUTPUT_FILE "${CMAKE_BINARY_DIR}/shaders/${SHADER_NAME}.metallib")

        add_custom_command(
            OUTPUT ${OUTPUT_FILE}
            COMMAND xcrun -sdk macosx metal -c ${INPUT_FILE} -o ${OUTPUT_FILE}
            DEPENDS ${INPUT_FILE}
            COMMENT "Compiling Metal shader: ${SHADER_NAME}"
        )

        list(APPEND COMPILED_SHADERS ${OUTPUT_FILE})
    endforeach()

    add_custom_target(CompileMetalShaders ALL DEPENDS ${COMPILED_SHADERS})
endfunction()

# LESSON LEARNED: Compile shaders before main target
if(APPLE)
    compile_metal_shaders()
    add_dependencies(PnbtrJellieTrainer CompileMetalShaders)

    # Copy shaders to app bundle
    add_custom_command(TARGET PnbtrJellieTrainer POST_BUILD
        COMMAND ${CMAKE_COMMAND} -E copy_directory
        ${CMAKE_BINARY_DIR}/shaders
        $<TARGET_BUNDLE_DIR:PnbtrJellieTrainer>/Contents/Resources/shaders
    )
endif()

# Platform-specific settings
if(APPLE)
    set_target_properties(PnbtrJellieTrainer PROPERTIES
        MACOSX_BUNDLE TRUE
        MACOSX_BUNDLE_BUNDLE_NAME "PNBTR+JELLIE Training Testbed"
        MACOSX_BUNDLE_GUI_IDENTIFIER "com.jamnet.pnbtrjellietrainer"
        XCODE_ATTRIBUTE_CODE_SIGN_IDENTITY ""
        XCODE_ATTRIBUTE_CODE_SIGNING_REQUIRED "NO"
    )
endif()
```

### **Build Script with Error Handling**

```bash
#!/bin/bash
# build_pnbtr_jellie.sh

set -e  # Exit on any error

echo "üîß Building PNBTR+JELLIE Training Testbed..."

# Create build directory
mkdir -p build
cd build

# Configure with CMake
echo "üìã Configuring CMake..."
cmake .. -DCMAKE_BUILD_TYPE=Release

# LESSON LEARNED: Check for Metal shader compilation
echo "üî® Compiling Metal shaders..."
make CompileMetalShaders

# Build main application
echo "üèóÔ∏è Building application..."
make -j$(sysctl -n hw.ncpu)

# LESSON LEARNED: Verify all required components
echo "‚úÖ Verifying build..."
if [ -f "PnbtrJellieTrainer.app/Contents/MacOS/PnbtrJellieTrainer" ]; then
    echo "‚úÖ Application built successfully"
else
    echo "‚ùå Application build failed"
    exit 1
fi

if [ -d "PnbtrJellieTrainer.app/Contents/Resources/shaders" ]; then
    echo "‚úÖ Metal shaders integrated successfully"
else
    echo "‚ùå Metal shaders missing"
    exit 1
fi

echo "üöÄ Build complete! Run with:"
echo "   open PnbtrJellieTrainer.app"
```

---

## ‚ö†Ô∏è **CRITICAL INTEGRATION RULES**

### **CRITICAL TRANSPORT BAR LAYOUT FIX**

**ISSUE**: Transport bar and UI components can break if row heights are inconsistent between `paint()` and `resized()` methods.

**SYMPTOMS**: Transport bar missing, UI layout broken, components not visible

**ROOT CAUSE**: Inconsistent `rowHeights` arrays and missing component allocations

**SOLUTION**:

```cpp
// MainComponent.cpp - CONSISTENT row heights in BOTH methods

void MainComponent::paint(juce::Graphics& g) {
    // CRITICAL: Must match resized() exactly
    const int rowHeights[] = {48, 32, 200, 160, 160, 100, 60};
    int y = 0;
    for (int i = 0; i < 6; ++i) {
        y += rowHeights[i];
        g.drawLine(0.0f, (float)y, (float)getWidth(), (float)y, 1.0f);
    }
}

void MainComponent::resized() {
    // CRITICAL: Must match paint() exactly
    const int rowHeights[] = {48, 32, 200, 160, 160, 100, 60};

    // CRITICAL: Allocate ALL components created in initialization
    if (transportBar) transportBar->setBounds(area.removeFromTop(rowHeights[0]));
    auto deviceBar = area.removeFromTop(rowHeights[1]);
    if (inputDeviceBox) inputDeviceBox->setBounds(deviceBar.removeFromLeft(getWidth() / 2).reduced(8, 4));
    if (outputDeviceBox) outputDeviceBox->setBounds(deviceBar.reduced(8, 4));
    if (oscilloscopeRow) oscilloscopeRow->setBounds(area.removeFromTop(rowHeights[2]));
    if (jellieTrack) jellieTrack->setBounds(area.removeFromTop(rowHeights[3]));
    if (pnbtrTrack) pnbtrTrack->setBounds(area.removeFromTop(rowHeights[4]));
    if (metricsDashboard) metricsDashboard->setBounds(area.removeFromTop(rowHeights[5]));

    // CRITICAL: Don't forget controlsRow - this causes layout corruption!
    if (controlsRow) controlsRow->setBounds(area.removeFromTop(rowHeights[6]));
}
```

### **CRITICAL MICROPHONE PERMISSION FIX (macOS)**

**ISSUE**: Audio input not working on macOS due to missing microphone permissions

**SYMPTOMS**: No audio input signal, oscilloscopes not responding, record arming doesn't capture audio

**ROOT CAUSE**: macOS requires explicit microphone permission requests and proper input channel configuration

**SOLUTION**:

```cpp
// MainComponent.cpp - Audio device initialization with permissions

case 10: {
    // CRITICAL FOR macOS: Request microphone permissions explicitly
    #if JUCE_MAC
    juce::RuntimePermissions::request(juce::RuntimePermissions::recordAudio,
        [this](bool granted) {
            if (granted) {
                printf("[PERMISSIONS] ‚úÖ Microphone permission granted!\n");
            } else {
                printf("[PERMISSIONS] ‚ùå Microphone permission denied!\n");
            }
        });
    #endif

    // CRITICAL: Enable input channels explicitly (2 in, 2 out, request permissions)
    juce::String error = deviceManager.initialise(2, 2, nullptr, true);

    if (error.isNotEmpty()) {
        // Try fallback with minimal settings
        error = deviceManager.initialise(1, 2, nullptr, false);
    }

    // CRITICAL: Add audio callback BEFORE device configuration
    deviceManager.addAudioCallback(this);

    // CRITICAL: Explicitly configure input device if not selected
    auto setup = deviceManager.getAudioDeviceSetup();
    if (setup.inputDeviceName.isEmpty()) {
        auto* deviceType = deviceManager.getAvailableDeviceTypes()[0];
        auto inputDevices = deviceType->getDeviceNames(true);
        if (!inputDevices.isEmpty()) {
            setup.inputDeviceName = inputDevices[0];
            setup.useDefaultInputChannels = true;
            deviceManager.setAudioDeviceSetup(setup, true);
        }
    }
    break;
}
```

### **CRITICAL AUDIO CALLBACK DEBUG PATTERN**

**ISSUE**: Audio input not reaching Metal shaders due to silent callback failures

**SOLUTION**:

```cpp
void MainComponent::audioDeviceIOCallback(const float** inputChannelData, int numInputChannels,
                                          float** outputChannelData, int numOutputChannels, int numSamples) {
    // CRITICAL: Always log first few callbacks to verify execution
    static int callbackCount = 0;
    if (callbackCount < 5) {
        printf("[AUDIO CALLBACK #%d] CHANNELS IN:%d OUT:%d SAMPLES:%d\n",
               callbackCount + 1, numInputChannels, numOutputChannels, numSamples);
        fflush(stdout);  // Force immediate console output
    }

    // CRITICAL: Show input levels to verify signal presence
    if (++callbackCount % 1000 == 0 && inputChannelData && numInputChannels > 0) {
        float inputLevel = 0.0f;
        for (int i = 0; i < numSamples; ++i) {
            inputLevel = std::max(inputLevel, std::abs(inputChannelData[0][i]));
        }
        if (inputLevel > 0.001f) {
            printf("[AUDIO] Input level detected: %.4f\n", inputLevel);
        } else {
            printf("[AUDIO] No input signal detected\n");
        }
        fflush(stdout);
    }
}
```

### **CRITICAL TRACK RECORD ARM BUTTON IMPLEMENTATION**

**ISSUE**: Tracks have record arm logic but no user-clickable controls

**SYMPTOMS**: Users can't arm tracks for recording, no visible record arm buttons

**ROOT CAUSE**: SpectralAudioTrack has setRecordArmed() functionality but missing GUI controls

**SOLUTION**:

```cpp
// SpectralAudioTrack.h - Add record arm button declaration
class SpectralAudioTrack : public juce::Component, public juce::Timer {
    // ... existing members ...

    // ADDED: Record arm button for user interaction
    std::unique_ptr<juce::TextButton> recordArmButton;
};

// SpectralAudioTrack.cpp - Constructor creates clickable record arm button
SpectralAudioTrack::SpectralAudioTrack(TrackType type, const std::string& trackName) {
    // ... existing initialization ...

    // ADDED: Create record arm button
    recordArmButton = std::make_unique<juce::TextButton>("R");
    recordArmButton->setButtonText("R");
    recordArmButton->setClickingTogglesState(true);
    recordArmButton->setColour(juce::TextButton::buttonColourId, juce::Colours::darkgrey);
    recordArmButton->setColour(juce::TextButton::buttonOnColourId, juce::Colours::red);
    recordArmButton->setColour(juce::TextButton::textColourOffId, juce::Colours::white);
    recordArmButton->setColour(juce::TextButton::textColourOnId, juce::Colours::white);
    recordArmButton->onClick = [this] {
        bool armed = recordArmButton->getToggleState();
        setRecordArmed(armed);

        // Auto-start recording when armed and transport is playing
        if (armed && pnbtrTrainer && pnbtrTrainer->isTrainingActive()) {
            startRecording();
        }
    };
    addAndMakeVisible(recordArmButton.get());
}

// SpectralAudioTrack.cpp - Position button in header area
void SpectralAudioTrack::resized() {
    auto bounds = getLocalBounds();
    headerArea = bounds.removeFromTop(20);
    controlsArea = bounds.removeFromBottom(15);

    // ADDED: Position record arm button in header area
    if (recordArmButton) {
        auto buttonArea = headerArea.removeFromRight(25).reduced(2);
        recordArmButton->setBounds(buttonArea);
    }

    // Split remaining area between waveform and spectrum
    auto remainingHeight = bounds.getHeight();
    waveformArea = bounds.removeFromTop(remainingHeight * 0.6f);
    spectrumArea = bounds;
}

// SpectralAudioTrack.cpp - Sync button state with record armed status
void SpectralAudioTrack::setRecordArmed(bool armed) {
    recordArmed = armed;

    // ADDED: Sync button state with record armed status
    if (recordArmButton) {
        recordArmButton->setToggleState(armed, juce::dontSendNotification);
    }

    if (!armed && recording) {
        stopRecording();
    }
}
```

**RESULT**: Each track now has a clickable "R" button that:

- Shows grey when disarmed, red when armed
- Toggles record arm state when clicked
- Auto-starts recording when armed during playback
- Syncs with programmatic record arm changes

### **CRITICAL RECORD ARM BUTTON IMPLEMENTATION**

**ISSUE**: Record arm buttons exist in UI but aren't connected to actual audio recording pipeline

**SYMPTOMS**:

- Buttons toggle visually but no audio recording occurs
- Metal shaders hardcoded to `true` instead of using actual button states
- UI state disconnected from audio processing pipeline

**ROOT CAUSE**: Missing connection between SpectralAudioTrack record arm buttons and MetalBridge GPU pipeline

**COMPLETE SOLUTION**:

#### **1. Add Record Arm State Methods to MainComponent**

```cpp
// MainComponent.h - Add methods to check track record arm states
private:
    // ADDED: Record arm state management for connecting UI to audio pipeline
    bool isJellieTrackRecordArmed() const;
    bool isPNBTRTrackRecordArmed() const;

// MainComponent.cpp - Implement the methods
bool MainComponent::isJellieTrackRecordArmed() const
{
    return jellieTrack ? jellieTrack->isRecordArmed() : false;
}

bool MainComponent::isPNBTRTrackRecordArmed() const
{
    return pnbtrTrack ? pnbtrTrack->isRecordArmed() : false;
}
```

#### **2. Update Audio Callback to Pass Record Arm States**

```cpp
// MainComponent.cpp - In audioDeviceIOCallback()
if (pnbtrTrainer) {
    try {
        juce::MidiBuffer midi;

        // CRITICAL FIX: Pass record arm states to the audio processor
        bool jellieRecordArmed = isJellieTrackRecordArmed();
        bool pnbtrRecordArmed = isPNBTRTrackRecordArmed();

        // Set record arm states in the trainer so GPU pipeline can respect them
        pnbtrTrainer->setJellieRecordArmed(jellieRecordArmed);
        pnbtrTrainer->setPNBTRRecordArmed(pnbtrRecordArmed);

        pnbtrTrainer->processBlock(buffer, midi);
    } catch (const std::exception& e) {
        juce::Logger::writeToLog("[AUDIO CALLBACK] Exception: " + juce::String(e.what()));
    }
}
```

#### **3. Add Record Arm Management to PNBTRTrainer**

```cpp
// PNBTRTrainer.h - Add record arm setter methods and storage
public:
    // ADDED: Record arm state management for connecting UI to GPU pipeline
    void setJellieRecordArmed(bool armed) { jellieRecordArmed.store(armed); }
    void setPNBTRRecordArmed(bool armed) { pnbtrRecordArmed.store(armed); }
    bool isJellieRecordArmed() const { return jellieRecordArmed.load(); }
    bool isPNBTRRecordArmed() const { return pnbtrRecordArmed.load(); }

private:
    // ADDED: Record arm state storage
    std::atomic<bool> jellieRecordArmed{false};
    std::atomic<bool> pnbtrRecordArmed{false};
```

#### **4. Connect PNBTRTrainer to MetalBridge**

```cpp
// PNBTRTrainer.cpp - In processBlock() before GPU processing
// **CRITICAL FIX: Pass record arm states to MetalBridge before processing**
MetalBridge::getInstance().setRecordArmStates(
    jellieRecordArmed.load(),
    pnbtrRecordArmed.load()
);
```

#### **5. Update MetalBridge to Use Actual Record Arm States**

```cpp
// MetalBridge.h - Add record arm state management
public:
    // ADDED: Record arm state management for GPU pipeline
    void setRecordArmStates(bool jellieArmed, bool pnbtrArmed);

private:
    // ADDED: Record arm states for GPU pipeline
    bool jellieRecordArmed = false;
    bool pnbtrRecordArmed = false;

// MetalBridge.mm - Implement the method
void MetalBridge::setRecordArmStates(bool jellieArmed, bool pnbtrArmed) {
    jellieRecordArmed = jellieArmed;
    pnbtrRecordArmed = pnbtrArmed;
}
```

#### **6. Fix GPU Pipeline to Use Actual States**

```cpp
// MetalBridge.mm - In runSevenStageProcessingPipeline()
void MetalBridge::runSevenStageProcessingPipeline(size_t numSamples) {
    @autoreleasepool {
        id<MTLCommandBuffer> commandBuffer = [commandQueue commandBuffer];

        // FIXED: Use the stored record arm states from setRecordArmStates()
        bool jellieArmed = jellieRecordArmed;
        bool pnbtrArmed = pnbtrRecordArmed;

        // Stage 1: Input Capture - Use actual JELLIE record arm state
        if (inputCapturePipeline) {
            // ... setup encoder ...
            [encoder setBytes:&jellieArmed length:sizeof(bool) atIndex:3];
            // ...
        }

        // Stage 4: Record Arm Visual - Use actual PNBTR record arm state
        if (recordArmPipeline) {
            // ... setup encoder ...
            [encoder setBytes:&pnbtrArmed length:sizeof(bool) atIndex:2];
            // ...
        }
    }
}
```

**RESULT**: Record arm buttons now properly control GPU audio recording pipeline

**DATA FLOW**:

```
SpectralAudioTrack buttons ‚Üí MainComponent ‚Üí PNBTRTrainer ‚Üí MetalBridge ‚Üí GPU shaders
```

**TESTING**:

1. Click record arm buttons on tracks - they should turn red when armed
2. Press Play in transport bar to start training
3. Speak into microphone - audio should only be captured for record-armed tracks
4. GPU shaders now respect actual UI record arm states instead of hardcoded values

### **Memory Management**

1. **NEVER** allocate memory in audio callback thread
2. **ALWAYS** use pre-allocated buffers with bounds checking
3. **VERIFY** `std::min(bufferSize, SAFE_BUFFER_SIZE)` before processing
4. **INITIALIZE** all arrays with `memset()` to avoid garbage data

### **Threading**

1. **AUDIO THREAD**: Only Metal compute, atomics, no locks
2. **UI THREAD**: Timer-based updates (30-60 FPS), never block audio
3. **COMMUNICATION**: Atomic variables for simple data, mutex for complex structs
4. **PRIORITY**: Real-time audio thread priority, never wait for UI

### **GPU Resource Management**

1. **INITIALIZE**: All Metal resources during app startup
2. **REUSE**: Buffers and textures, never create in real-time
3. **SYNCHRONIZE**: Command buffer completion before buffer reuse
4. **CLEANUP**: All Metal objects in destructor with proper reference counting

### **JUCE Integration**

1. **DSP MODULE**: Always link `juce::juce_dsp` for FFT functionality
2. **DEPRECATED**: Use `std::min/max/clamp` instead of `jmin/jmax`
3. **COMPONENTS**: Use address-of operator for `addAndMakeVisible(&component)`
4. **AUDIO DEVICE**: Verify `numInputChannels > 0` in audio callback

### **Build Process**

1. **COMPILE**: Metal shaders before C++ compilation
2. **BUNDLE**: Include `.metallib` files in app bundle
3. **LINK**: Metal framework after JUCE libraries
4. **TEST**: Verify shader loading during Metal initialization

---

## üéØ **PERFORMANCE TARGETS**

### **Real-Time Constraints**

- **Audio Latency**: < 5ms (128 samples @ 48kHz)
- **UI Responsiveness**: 30-60 FPS interface updates
- **CPU Utilization**: < 50% on recommended hardware
- **Memory Usage**: < 500MB for full processing pipeline
- **GPU Utilization**: Efficient Metal compute with < 10% GPU usage

### **Quality Metrics**

- **Audio Quality**: > 20 dB SNR reconstruction
- **Stability**: 24+ hour continuous operation
- **Real-Time Safety**: Zero audio dropouts under normal load
- **Scalability**: Support for 8+ parallel processing chains

---

## üöÄ **QUICK START CHECKLIST**

### **Development Setup**

- [ ] macOS 12+ with Xcode 14+
- [ ] CMake 3.22+
- [ ] JUCE 7.0+ installed
- [ ] Metal development tools

### **Project Setup**

- [ ] Copy complete CMakeLists.txt configuration
- [ ] Create Metal shader directory structure
- [ ] Implement MetalBridge singleton
- [ ] Set up thread-safe parameter management

### **Build Verification**

- [ ] Metal shaders compile to .metallib files
- [ ] Application builds without linker errors
- [ ] All GUI components initialize properly
- [ ] Audio device callback processes without dropouts
- [ ] Metal compute pipeline executes successfully

### **Testing Protocol**

- [ ] Audio input/output functional
- [ ] Real-time spectral analysis working
- [ ] Network simulation parameters adjustable
- [ ] PNBTR reconstruction audible
- [ ] All visualizations updating at correct frame rates

**This comprehensive guide eliminates the trial-and-error development cycle by incorporating all lessons learned from production implementation of the PNBTR+JELLIE Training Testbed.**
