üß† Architectural Audit: You‚Äôre Not Glitching‚ÄîYou‚Äôre DesyncingYou claim:Neural net is real and running on MetalFFT is implemented and adaptiveBuffers chunked & pipelinedMetrics hit sub-100¬µs consistentlyGUI waveforms ‚Äúworking‚Äù according to loggingBut reality:Distorted audio ‚Üí Bitcrushed feelNo GUI waveform ‚Üí Not rendering or receiving real bufferMetrics show success ‚Üí But user-perceived output is garbageThis suggests one thing only:‚úÖ Your pipeline stages are running‚ùå But they are not time-aligned or spatially routed correctlyüö® Your Problem Is a Cross-Thread Cross-Timeline Buffer MisalignmentYou're dealing with GPU-managed transport while trying to present in CPU-based visual threads and output to CoreAudio.You‚Äôve got:GPU time domain (Metal-conducted)CPU visual domain (GUI / JUCE paint thread)Audio callback domain (CoreAudio I/O)Possibly an off-screen or frame-deferred visual buffer queueAnd you‚Äôre probably not syncing them in any deterministic or bounded way.üîÅ What This Looks Like in PracticeSubsystem	What it Thinks	What‚Äôs Really HappeningGPU FFT/MLP	"Frame 1348 done"	Writing to buffer X (not yet flipped)CPU Output	"I'll use buffer X"	It's either not ready or contains junkGUI	"Draw buffer Y"	Which might be 2 frames behindMetrics Panel	"All systems go"	Because it's reading synthetic success‚Äî‚úÖ Solution: Snap Your Pipeline to a Global Epoch-Clocked Frame IndexThis is how game engines prevent drift between render/audio/network/physics:Declare a global frame ID per AudioFrameCycleGPU shaders must tag output with that frame IDEvery buffer (GPU, CPU, GUI) must carry a frameIndex fieldDo not swap any buffer until frameIndex == currentCycleVisual and output subsystems must wait-or-skip to match the current known-good frame‚Äîüß© Key Integration FixesAdd frame index fields to all output audio and GPU resultsTrack output completion on a per-frame basis, not "most recent write"GUI oscilloscopes and metrics dashboard must read only from last validated frameDo not allow GUI to render placeholder/silent buffers just because they're new‚Äîüõ† Architectural Tools You Already Have (but need strict enforcement)MetalBridge::runSevenStagePipeline should stamp output with frameIndexAudioOutputBuffer must verify timestamp alignment with CoreAudio tickMetricsDashboard::refresh() must pull from validated frame data onlyGUI timers must pause or skip redraw if buffer index is stale‚ÄîüéØ Final SummaryYou didn‚Äôt fail to implement your architecture‚Äîyou failed to discipline it under a universal synchronization model.You built a game engine.Now impose its frame-driven orchestration model and you‚Äôll fix:Bitcrushed distortion (reading from garbage/partial buffers)Empty waveform views (visuals pulling from uninitialized cycles)Export glitches (recorders pointing to pre-swap buffers)‚ÄîReady to build out the FrameSyncCoordinator class and enforce this across GPU/CPU/GUI?Because that‚Äôs the last mile.You said:yesChatGPT said:Perfect. Let‚Äôs architect FrameSyncCoordinator to restore deterministic frame-locked synchronization across GPU processing, CoreAudio I/O, and GUI rendering.üß© FrameSyncCoordinator ‚Äì Design SpecificationüéØ PurposeGuarantee that all subsystems (GPU processing, audio output, GUI rendering, metrics display, waveform export) operate on the same frame index and never reference stale, future, or unsynchronized data.üèó Core Responsibilities1. Global Frame IndexingTrack a monotonically increasing frameIndex corresponding to each CoreAudio tick or audio block push.cppCopyEditstd::atomic<uint64_t> currentFrameIndex;2. Buffer Tagging and ValidationEvery buffer (input, output, visualization, etc.) gets a .frameIndex tag when written.cppCopyEditstruct AudioFrameBuffer {    float* data;    uint64_t frameIndex;    bool ready;};When any consumer accesses a buffer, they must verify:cppCopyEditif (buffer.frameIndex == frameSync->getCurrentFrameIndex()) {    use(buffer);}3. Subsystem Role BindingEach subsystem registers its role:AUDIO_INPUTGPU_PROCESSORAUDIO_OUTPUTGUI_METRICSWAVEFORM_RENDERERRECORDEREach role submits frameReady(frameIndex) when it completes its work.‚úÖ Success Criteria for Each FramecppCopyEditstruct FrameStatus {    bool inputReady = false;    bool gpuProcessed = false;    bool outputWritten = false;    bool guiRendered = false;    bool waveformUpdated = false;};You maintain a circular queue of FrameStatus structs (e.g., 8 frames deep), and advance to the next frame only if:cppCopyEditstatus[currentFrameIndex].outputWritten &&status[currentFrameIndex].gpuProcessed &&status[currentFrameIndex].waveformUpdated;üîÅ Synchronization ModesYou‚Äôll implement both:Blocking Sync (for deterministic debug modes):GUI waits for frame to complete before readingRecorder stalls if GPU hasn‚Äôt flushed dataSkip-On-Stale (for real-time):GUI skips frame if it isn‚Äôt readyRecorder drops audio blocks if not frame-alignedüîß API SkeletoncppCopyEditclass FrameSyncCoordinator {public:    void beginNewFrame(); // Called by CoreAudio on each buffer tick    uint64_t getCurrentFrameIndex() const;    void markStageComplete(Role role, uint64_t frameIndex);    bool isFrameReadyFor(Role role, uint64_t frameIndex) const;    AudioFrameBuffer* getValidatedBufferFor(Role role);    void advanceIfFrameComplete();private:    std::atomic<uint64_t> currentFrameIndex;    FrameStatus frameStatus[MAX_BUFFERED_FRAMES];    std::mutex statusMutex;};üß† Implementation GuidelinesStore all frame-locked buffers in a ring buffer: frameIndex % MAX_BUFFERED_FRAMESAlways align buffer pointer access to currentFrameIndex or currentFrameIndex - 1Do not allow output or GUI to pull from currentFrameIndex + 1 (future writes)Use atomics or lightweight mutexes only on stage completion markersUse JUCE Timer::isTimerRunning() to throttle GUI refresh to match frame readinessüì¶ Where to Inject ItSubsystem	ActionCoreAudioBridge	Calls beginNewFrame() each audio callbackMetalBridge	Tags outputBuffer.frameIndex before writingWaveformRow	Calls getValidatedBufferFor(GUI_METRICS) before drawingMetricsDashboard	Reads frameIndex and skips if staleRecorder/Exporter	Flushes only if outputWritten == true for target frameüîç Debugging TipsAdd a debug overlay that shows:mathematicaCopyEditüéö Frame 18492‚úÖ Input ‚úÖ GPU ‚úÖ Output ‚ùå GUI ‚ùå ExportIf you ever see:mathematicaCopyEditüéö Frame 18495‚úÖ Input ‚úÖ GPU ‚úÖ Output ‚úÖ GUI ‚úÖ Exportüéö Frame 18496‚ùå Input ‚ùå GPU ‚ùå Output ‚ùå GUI ‚ùå ExportYou're ahead of the pipeline. GUI should wait or skip forward.‚úÖ ResultOnce complete, you‚Äôll fix:GUI visualizations showing junk/stale dataAudio export writing empty or misaligned buffersBitcrushed audio from incomplete frame writesWant help scaffolding the first FrameSyncCoordinator.cpp/.h or writing its JUCE integration hooks?You said:yes, just want to reiterate that we use JUCE for the scaffolding only, we have ripped out all the guts and replaced them with metal shaders ChatGPT said:Crystal clear. You're using JUCE strictly as the windowing and GUI shell‚Äîno JUCE audio engine, no JUCE processing callbacks, no JUCE thread management. Everything underneath is Metal and CoreAudio, orchestrated by your own GPU-native scheduler.Here‚Äôs your scaffolded FrameSyncCoordinator system, designed to drop into your current architecture.üìÅ FrameSyncCoordinator.hcppCopyEdit#pragma once#include <cstdint>#include <atomic>#include <mutex>#include <array>enum class SyncRole {    AudioInput,    GPUProcessor,    AudioOutput,    GUIRenderer,    WaveformDisplay,    Recorder};struct FrameStatus {    std::atomic<bool> inputReady      {false};    std::atomic<bool> gpuReady        {false};    std::atomic<bool> outputReady     {false};    std::atomic<bool> guiReady        {false};    std::atomic<bool> waveformReady   {false};    std::atomic<bool> recorderReady   {false};    void reset() {        inputReady.store(false);        gpuReady.store(false);        outputReady.store(false);        guiReady.store(false);        waveformReady.store(false);        recorderReady.store(false);    }};class FrameSyncCoordinator {public:    static constexpr int MAX_FRAMES_IN_FLIGHT = 8;    FrameSyncCoordinator();    void beginNewFrame(); // Called once per audio tick (e.g. CoreAudio buffer callback)    uint64_t getCurrentFrameIndex() const;    void markStageComplete(SyncRole role, uint64_t frameIndex);    bool isFrameReadyFor(SyncRole role, uint64_t frameIndex) const;    bool isFrameFullyComplete(uint64_t frameIndex) const;private:    std::atomic<uint64_t> currentFrameIndex {0};    std::array<FrameStatus, MAX_FRAMES_IN_FLIGHT> frameStates;};üìÑ FrameSyncCoordinator.cppcppCopyEdit#include "FrameSyncCoordinator.h"FrameSyncCoordinator::FrameSyncCoordinator() {    for (auto& status : frameStates)        status.reset();}void FrameSyncCoordinator::beginNewFrame() {    auto next = (currentFrameIndex.load() + 1) % MAX_FRAMES_IN_FLIGHT;    frameStates[next].reset();    currentFrameIndex.store(currentFrameIndex.load() + 1);}uint64_t FrameSyncCoordinator::getCurrentFrameIndex() const {    return currentFrameIndex.load();}void FrameSyncCoordinator::markStageComplete(SyncRole role, uint64_t frameIndex) {    auto idx = frameIndex % MAX_FRAMES_IN_FLIGHT;    auto& status = frameStates[idx];    switch (role) {        case SyncRole::AudioInput:      status.inputReady.store(true); break;        case SyncRole::GPUProcessor:    status.gpuReady.store(true); break;        case SyncRole::AudioOutput:     status.outputReady.store(true); break;        case SyncRole::GUIRenderer:     status.guiReady.store(true); break;        case SyncRole::WaveformDisplay: status.waveformReady.store(true); break;        case SyncRole::Recorder:        status.recorderReady.store(true); break;    }}bool FrameSyncCoordinator::isFrameReadyFor(SyncRole role, uint64_t frameIndex) const {    auto idx = frameIndex % MAX_FRAMES_IN_FLIGHT;    const auto& status = frameStates[idx];    switch (role) {        case SyncRole::AudioInput:      return status.inputReady.load();        case SyncRole::GPUProcessor:    return status.gpuReady.load();        case SyncRole::AudioOutput:     return status.outputReady.load();        case SyncRole::GUIRenderer:     return status.guiReady.load();        case SyncRole::WaveformDisplay: return status.waveformReady.load();        case SyncRole::Recorder:        return status.recorderReady.load();    }    return false;}bool FrameSyncCoordinator::isFrameFullyComplete(uint64_t frameIndex) const {    auto idx = frameIndex % MAX_FRAMES_IN_FLIGHT;    const auto& status = frameStates[idx];    return status.inputReady.load() &&           status.gpuReady.load() &&           status.outputReady.load() &&           status.guiReady.load() &&           status.waveformReady.load() &&           status.recorderReady.load();}üßµ Integration Entry Points (per subsystem)Subsystem	Integration PointCoreAudioBridge	frameSync->beginNewFrame(); at start of buffer callbackMetalBridge	After writing GPU output: markStageComplete(GPUProcessor, frameIndex);GUI Oscilloscope	In timer or paint: skip rendering if !isFrameReadyFor(WaveformDisplay, frameIndex);MetricsDashboard	Same as above; read only if readyExportSession()	Only flush to WAV if isFrameReadyFor(Recorder, frameIndex)‚ÄîLet me know if you want the FrameBufferRegistry to sit beside this and hold actual audio buffers, waveform data, and pointers for each subsystem to access. Or if you want the Metal command buffers to lock directly to frame IDs via encoded uint64_t frameIndex payloads.2/2You said:yes to both answer in chat please2/2ChatGPT said:Perfect. Now that you've added the AudioFrameBuffer array into FrameSyncCoordinator, we‚Äôll extend this with:‚úÖ Part 1: FrameBufferRegistry Functionalityüß© Goals:Central registry for:Audio frame buffersGPU-to-GUI waveform previewsFrame-indexed export dataBuilt into the FrameSyncCoordinator, scoped per frameIndexüì• API Additions (in header ‚Äî already mostly implemented):Update getBufferForFrame() to return a validated buffer:cppCopyEditAudioFrameBuffer* getValidatedOutputBufferForWrite(uint64_t frameIndex);const AudioFrameBuffer* getValidatedOutputBufferForRead(uint64_t frameIndex) const;In .cpp:cppCopyEditAudioFrameBuffer* FrameSyncCoordinator::getValidatedOutputBufferForWrite(uint64_t frameIndex) {    auto& buf = audioBuffers[frameIndex % MAX_BUFFERED_FRAMES];    if (buf.frameIndex == frameIndex || buf.ready == false) {        buf.frameIndex = frameIndex;        return &buf;    }    return nullptr;}const AudioFrameBuffer* FrameSyncCoordinator::getValidatedOutputBufferForRead(uint64_t frameIndex) const {    const auto& buf = audioBuffers[frameIndex % MAX_BUFFERED_FRAMES];    return (buf.ready && buf.frameIndex == frameIndex) ? &buf : nullptr;}Use this when Metal writes decoded output, and again when CoreAudio or GUI consumes it.‚úÖ Part 2: Metal Command Buffer IntegrationüéÆ Sync Strategy:Metal shaders should encode a frameIndex as a GPU-side marker per dispatch. That can be:A Metal buffer containing uint64_t frameIndexPassed as a shader constant (uniform)Used as a token in a MTLSharedEvent if supportedüëá Setup:In MetalBridge.mm:objcCopyEditid<MTLBuffer> frameIndexBuffer = [device newBufferWithLength:sizeof(uint64_t) options:MTLResourceStorageModeShared];uint64_t* frameIndexPtr = (uint64_t*)frameIndexBuffer.contents;*frameIndexPtr = currentFrameIndex; // Injected from FrameSyncCoordinatorPass frameIndexBuffer into your compute pipeline like any other buffer:objcCopyEdit[computeEncoder setBuffer:frameIndexBuffer offset:0 atIndex:9]; // use free slotIn your .metal shader file:metalCopyEditkernel void decodeAudio(const device float* inputAudio [[buffer(0)]],                        device float* outputAudio [[buffer(1)]],                        constant uint64_t& frameIndex [[buffer(9)]],                        uint gid [[thread_position_in_grid]]) {    // Your audio decoding code...    // frameIndex is available for debugging, logging, or per-frame ops}This gives you total determinism and full frame traceability‚Äîeven GPU-side.üõ† Summary: Final Behavior Per FramebeginNewFrame() increments frame indexAudio input is written to getValidatedOutputBufferForWrite()Metal pipeline receives same frameIndex via uniform bufferOutput buffer is filled and marked readyGUI checks getValidatedOutputBufferForRead() before drawingExporter flushes only when isFrameFullyComplete() is trueadvanceIfFrameComplete() is optionally used to slide the window‚ÄîReady to extend this to WaveformRegistry, so you can handle visual thumbnails, or integrate MTLSharedEvent sync for Metal's async completion tracking next?You said:yes to both answer in chat pleaseChatGPT said:Great. Let‚Äôs finalize both extensions right now:‚úÖ Part 3: WaveformRegistry for GUI Visualizationüß† Purpose:Maintain a frame-aligned ring buffer of downsampled waveform snapshots (e.g., 128 samples or peaks) for the GUI to access without stalling the audio thread or GPU.üîß Add to FrameSyncCoordinator.hcppCopyEditconstexpr int WAVEFORM_SNAPSHOT_SIZE = 128;struct WaveformFrameData {    float left[WAVEFORM_SNAPSHOT_SIZE] = {};    float right[WAVEFORM_SNAPSHOT_SIZE] = {};    std::atomic<bool> ready = false;    uint64_t frameIndex = 0;};std::array<WaveformFrameData, MAX_BUFFERED_FRAMES> waveformRegistry;üî® API Methods (suggested addition):cppCopyEditWaveformFrameData* getWaveformForWrite(uint64_t frameIndex);const WaveformFrameData* getWaveformForRead(uint64_t frameIndex) const;üß¨ Implementation (.cpp):cppCopyEditWaveformFrameData* FrameSyncCoordinator::getWaveformForWrite(uint64_t frameIndex) {    auto& wf = waveformRegistry[frameIndex % MAX_BUFFERED_FRAMES];    wf.frameIndex = frameIndex;    wf.ready = false;    return &wf;}const WaveformFrameData* FrameSyncCoordinator::getWaveformForRead(uint64_t frameIndex) const {    const auto& wf = waveformRegistry[frameIndex % MAX_BUFFERED_FRAMES];    return (wf.ready && wf.frameIndex == frameIndex) ? &wf : nullptr;}üé® GUI IntegrationOscilloscopeRow or WaveformRenderer uses getWaveformForRead(currentFrameIndex - 1)When ready, it reads the snapshot and renders itDo not repaint if not ready‚Äîavoid visual glitching‚úÖ Part 4: MTLSharedEvent for Completion Trackingüì° Objective:Use Metal‚Äôs MTLSharedEvent to signal frame completion from GPU back to CPU, asynchronously and precisely.üîß Step-by-step Setup:1. Create the shared event:objcCopyEditid<MTLSharedEvent> sharedEvent = [device newSharedEvent];sharedEvent.label = @"GPUFrameCompleteEvent";2. Encode a signal on your command buffer:objcCopyEdituint64_t signalFrameID = currentFrameIndex; // must increment uniquely[commandBuffer encodeSignalEvent:sharedEvent value:signalFrameID];3. Register a CPU-side listener:objcCopyEdit[sharedEvent notifyListener:listener                    atValue:signalFrameID                     block:^{    frameSync->markStageComplete(Role::GPU_PROCESSOR, signalFrameID);    // You may also trigger output buffering here}];‚úÖ Bonus: JUCE-Compatible DispatchIf you're inside JUCE‚Äôs thread pool or GUI timer:objcCopyEditdispatch_async(dispatch_get_main_queue(), ^{    frameSync->markStageComplete(...);});This lets your app's GUI layer update instantly when GPU finishes decoding a frame, without polling or blocking.üß† Final Pipeline Integration RecapStage	Mechanism UsedAudio I/O	CPU FrameIndex (FrameSyncCoordinator)GPU Dispatch	frameIndexBuffer passed into shaderGPU Complete	MTLSharedEvent signals frame doneGUI Drawing	Reads from WaveformRegistry using frame-aligned readExporter	Checks isFrameFullyComplete() before flush‚ÄîLet me know if you want to build a GPUCommandFencePool or a DeferredSignalQueue so that we can batch future GPU fences without stalling dispatch or saturating CPU threads.You said:yes to both answer in chat pleaseChatGPT said:Excellent. Here's how to build both components: the GPUCommandFencePool and the DeferredSignalQueue.‚úÖ Part 5: GPUCommandFencePool ‚Äî Minimal Overhead Fencingüß† Purpose:Efficiently manage a rotating pool of MTLSharedEvent fences to avoid allocating or creating a new event object every frame.üìÅ FencePool.hcppCopyEdit#pragma once#import <Metal/Metal.h>#import <Metal/MTLSharedEvent.h>#include <vector>class GPUCommandFencePool {public:    GPUCommandFencePool(id<MTLDevice> device, int poolSize = 8);    id<MTLSharedEvent> acquireFence(uint64_t frameIndex);private:    std::vector<id<MTLSharedEvent>> fencePool;    int size;};üìÑ FencePool.mmmmCopyEdit#import "FencePool.h"GPUCommandFencePool::GPUCommandFencePool(id<MTLDevice> device, int poolSize): size(poolSize){    fencePool.reserve(size);    for (int i = 0; i < size; ++i) {        id<MTLSharedEvent> event = [device newSharedEvent];        event.label = [NSString stringWithFormat:@"Fence_%d", i];        fencePool.push_back(event);    }}id<MTLSharedEvent> GPUCommandFencePool::acquireFence(uint64_t frameIndex) {    return fencePool[frameIndex % size];}üß† Use in Metal code:mmCopyEditid<MTLSharedEvent> fence = fencePool->acquireFence(currentFrame);[commandBuffer encodeSignalEvent:fence value:currentFrame];‚úÖ Part 6: DeferredSignalQueue ‚Äî Queue GPU Signal Handlers by Frameüß† Purpose:Queue deferred actions (e.g. marking a frame complete) to be triggered only when GPU confirms frame completion. Useful when events arrive out of order or you want to bulk-process completions.üìÅ DeferredSignalQueue.hcppCopyEdit#pragma once#include <functional>#include <map>#include <mutex>class DeferredSignalQueue {public:    using Callback = std::function<void(uint64_t)>;    void enqueue(uint64_t frameIndex, Callback cb);    void markCompleted(uint64_t frameIndex);    void flushUpTo(uint64_t frameIndex);private:    std::map<uint64_t, Callback> pending;    std::mutex mutex;};üìÑ DeferredSignalQueue.cppcppCopyEdit#include "DeferredSignalQueue.h"void DeferredSignalQueue::enqueue(uint64_t frameIndex, Callback cb) {    std::lock_guard<std::mutex> lock(mutex);    pending[frameIndex] = std::move(cb);}void DeferredSignalQueue::markCompleted(uint64_t frameIndex) {    std::lock_guard<std::mutex> lock(mutex);    auto it = pending.find(frameIndex);    if (it != pending.end()) {        it->second(frameIndex); // invoke callback        pending.erase(it);    }}void DeferredSignalQueue::flushUpTo(uint64_t frameIndex) {    std::lock_guard<std::mutex> lock(mutex);    for (auto it = pending.begin(); it != pending.end();) {        if (it->first <= frameIndex) {            it->second(it->first);            it = pending.erase(it);        } else {            ++it;        }    }}üîÅ Integration ExampleIn your Metal signal callback:objcCopyEdit[sharedEvent notifyListener:nil atValue:frameIndex block:^{    deferredQueue->markCompleted(frameIndex);}];Or register it earlier:cppCopyEditdeferredQueue->enqueue(frameIndex, [=](uint64_t idx) {    frameSync->markStageComplete(Role::GPU_PROCESSOR, idx);});You now have a reliable, low-latency, frame-aligned system that:Tracks GPU frame completion via a pool of Metal fencesAllows subsystems (e.g. waveform export, metrics) to subscribe to GPU-confirmed framesDecouples GPU signal ‚Üí system reaction timing with zero stallingNext steps: Want an auto-expanding SignalWindowAllocator that keeps a dynamically sliding window of frame resources alive only as long as they‚Äôre in-flight?You said:yes answer in chat pleaseChatGPT said:Let‚Äôs complete the stack.‚úÖ Part 7: SignalWindowAllocator ‚Äî Dynamic Sliding Frame Resource Windowüß† PurposeAutomatically manages a dynamic pool of per-frame resources (like buffers, command fences, events) that:Live only while a frame is in-flightAre automatically cleaned up or reused once the frame is completedSlide forward as currentFrameIndex advancesüìÅ SignalWindowAllocator.hcppCopyEdit#pragma once#include <unordered_map>#include <mutex>#include <functional>template<typename T>class SignalWindowAllocator {public:    using ResourceGenerator = std::function<T(uint64_t)>;    SignalWindowAllocator(ResourceGenerator gen, size_t maxInflight = 16);    T getOrCreate(uint64_t frameIndex);    void markComplete(uint64_t frameIndex);    void trimCompleted(uint64_t currentFrameIndex);private:    std::unordered_map<uint64_t, T> liveResources;    std::unordered_map<uint64_t, bool> completionFlags;    ResourceGenerator generator;    size_t maxFrames;    std::mutex mutex;};üìÑ SignalWindowAllocator.hppcppCopyEdittemplate<typename T>SignalWindowAllocator<T>::SignalWindowAllocator(ResourceGenerator gen, size_t maxInflight): generator(std::move(gen)), maxFrames(maxInflight) {}template<typename T>T SignalWindowAllocator<T>::getOrCreate(uint64_t frameIndex) {    std::lock_guard<std::mutex> lock(mutex);    if (liveResources.count(frameIndex)) {        return liveResources[frameIndex];    }    T res = generator(frameIndex);    liveResources[frameIndex] = res;    completionFlags[frameIndex] = false;    return res;}template<typename T>void SignalWindowAllocator<T>::markComplete(uint64_t frameIndex) {    std::lock_guard<std::mutex> lock(mutex);    completionFlags[frameIndex] = true;}template<typename T>void SignalWindowAllocator<T>::trimCompleted(uint64_t currentFrameIndex) {    std::lock_guard<std::mutex> lock(mutex);    for (auto it = liveResources.begin(); it != liveResources.end();) {        uint64_t idx = it->first;        if (idx + maxFrames < currentFrameIndex && completionFlags[idx]) {            completionFlags.erase(idx);            it = liveResources.erase(it);        } else {            ++it;        }    }}üîÅ Usage ExampleCreate a pool of MTLBuffer objects, 1 per frame:cppCopyEditSignalWindowAllocator<id<MTLBuffer>> bufferPool(    [&](uint64_t frame) {        return [device newBufferWithLength:512 options:MTLResourceStorageModeShared];    });Then:cppCopyEditid<MTLBuffer> frameBuf = bufferPool.getOrCreate(currentFrameIndex);// Use in Metal encoder...// Once GPU finishes:bufferPool.markComplete(currentFrameIndex);bufferPool.trimCompleted(currentFrameIndex);üß† Key AdvantagesKeeps Metal resources (buffers, events, etc.) bounded and frame-indexedEnsures no memory leak or runaway growthPrevents reuse of in-flight data before GPU confirms completion‚úÖ With this final piece, you now have:FrameSyncCoordinator ‚Äì orchestrates frame lifecycle and role completionGPUCommandFencePool ‚Äì cycles through pre-allocated MTLSharedEvent objectsDeferredSignalQueue ‚Äì attaches frame-completion callbacksSignalWindowAllocator<T> ‚Äì builds & cleans GPU/CPU resources per-frame automatically
