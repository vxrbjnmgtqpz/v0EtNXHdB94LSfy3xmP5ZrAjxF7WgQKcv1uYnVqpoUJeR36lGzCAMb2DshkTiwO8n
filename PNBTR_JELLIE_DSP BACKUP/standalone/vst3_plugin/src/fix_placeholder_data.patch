/*
 * PNBTR+JELLIE Training Testbed - Placeholder Data Fix Patch
 *
 * This patch ensures that real audio processing is used instead of placeholder data
 * Apply this to PnbtrJellieGUIApp_Fixed.mm if issues persist after rebuild
 */

// Add these definitions to the top of the file, after imports
#ifndef USE_REAL_PROCESSING
#define USE_REAL_PROCESSING 1
#endif

#ifndef DISABLE_PLACEHOLDER_DATA
#define DISABLE_PLACEHOLDER_DATA 1
#endif

/*
 * CHANGES NEEDED:
 *
 * 1. Find the updateRealTimeMetrics method and ensure it's using real data:
 
- (void)updateRealTimeMetrics {
    if (!audioData || !audioData->isProcessing) return;
    
    // Calculate real metrics from audio data
    float snr = calculateSNR(audioData->inputBuffer, audioData->reconstructedBuffer);
    float thd = calculateTHD(audioData->inputBuffer, audioData->reconstructedBuffer);
    float latency = calculateLatency(audioData->inputBuffer, audioData->reconstructedBuffer);
    
    int totalPackets = audioData->packetsProcessed.load();
    int lostPackets = audioData->packetsLost.load();
    
    float reconstructionRate = (totalPackets > 0) ? 100.0f * (1.0f - (float)lostPackets / totalPackets) : 100.0f;
    float gapFillQuality = calculateGapFillQuality(audioData->inputBuffer, audioData->reconstructedBuffer);
    float overallQuality = (snr + (100.0f - thd) + (100.0f - latency) + reconstructionRate + gapFillQuality) / 5.0f;
    
    // Update UI on main thread
    dispatch_async(dispatch_get_main_queue(), ^{
        [self updateMetricDisplay:@"SNR" value:snr bar:_snrBar];
        [self updateMetricDisplay:@"THD" value:thd bar:_thdBar];
        [self updateMetricDisplay:@"Latency" value:latency bar:_latencyBar];
        [self updateMetricDisplay:@"Reconstruction" value:reconstructionRate bar:_reconstructionBar];
        [self updateMetricDisplay:@"Gap Fill" value:gapFillQuality bar:_gapFillBar];
        [self updateMetricDisplay:@"Quality" value:overallQuality bar:_qualityBar];
        
        // Update status
        [_statusLabel setStringValue:[NSString stringWithFormat:
            @"üî¥ LIVE: SNR:%.1fdB THD:%.1f%% Latency:%.1fms Recon:%.1f%% Quality:%.1f%%",
            snr, thd, latency, reconstructionRate, overallQuality]];
            
        // Update waveform views with real data
        [_inputOscilloscope updateWithData:audioData->inputBuffer mutex:&audioData->bufferMutex color:[NSColor greenColor]];
        [_outputOscilloscope updateWithData:audioData->reconstructedBuffer mutex:&audioData->bufferMutex color:[NSColor cyanColor]];
    });
}

 * 2. In the setupAudio method, make sure audioData is properly initialized:
 
    // Init audio processing state
    audioData = new JAMNetAudioData();
    audioData->inputBuffer.resize(4096, 0.0f);
    audioData->reconstructedBuffer.resize(4096, 0.0f);
    audioData->isProcessing = false;
    audioData->packetsLost = 0;
    audioData->packetsProcessed = 0;
    
    // Always enable real microphone input
    if (!setupJAMNetAudio(audioData)) {
        [self addLogMessage:@"‚ùå Failed to setup audio system"];
        return false;
    }
 
 * 3. Make sure the Core Audio callbacks are working properly - check permissions:
 
 - Add microphone permission check:
 
    // Check microphone permissions
    AVAuthorizationStatus authStatus = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];
    if (authStatus != AVAuthorizationStatusAuthorized) {
        [AVCaptureDevice requestAccessForMediaType:AVMediaTypeAudio completionHandler:^(BOOL granted) {
            if (!granted) {
                NSLog(@"‚ùå Microphone permission denied");
                dispatch_async(dispatch_get_main_queue(), ^{
                    [self addLogMessage:@"‚ùå ERROR: Microphone permission denied"];
                });
            }
        }];
    }
*/
